# LangChain é›†æˆç¤ºä¾‹

MCPStore ä¸ LangChain çš„å®Œæ•´é›†æˆç¤ºä¾‹ï¼Œå±•ç¤ºå„ç§å®é™…åº”ç”¨åœºæ™¯ã€‚

## åŸºç¡€é›†æˆç¤ºä¾‹

### ç®€å•çš„å¤©æ°”æŸ¥è¯¢ Agent

```python
from mcpstore import MCPStore
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# 1. åˆå§‹åŒ– MCPStore å¹¶æ·»åŠ å¤©æ°”æœåŠ¡
store = MCPStore.setup_store()
store.for_store().add_service({
    "name": "weather-api",
    "url": "https://weather.example.com/mcp"
})

# 2. è·å– LangChain å·¥å…·
tools = store.for_store().for_langchain().list_tools()

# 3. åˆ›å»º LLM å’Œæç¤ºæ¨¡æ¿
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªå¤©æ°”åŠ©æ‰‹ï¼Œå¯ä»¥æŸ¥è¯¢å„åœ°å¤©æ°”ä¿¡æ¯ã€‚"),
    ("user", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

# 4. åˆ›å»º Agent å’Œæ‰§è¡Œå™¨
agent = create_openai_tools_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# 5. ä½¿ç”¨ Agent
response = agent_executor.invoke({"input": "åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"})
print(response["output"])
```

## å¼‚æ­¥é›†æˆç¤ºä¾‹

### å¼‚æ­¥å¤šæœåŠ¡ Agent

```python
import asyncio
from mcpstore import MCPStore
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

async def create_async_agent():
    # 1. å¼‚æ­¥åˆå§‹åŒ–å’ŒæœåŠ¡æ·»åŠ 
    store = MCPStore.setup_store()
    
    # å¼‚æ­¥æ·»åŠ å¤šä¸ªæœåŠ¡
    await store.for_store().add_service_async({
        "name": "sequential-thinking",
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-sequential-thinking"]
    })
    
    await store.for_store().add_service_async({
        "name": "filesystem",
        "command": "npx", 
        "args": ["-y", "filesystem-mcp"]
    })
    
    # 2. å¼‚æ­¥è·å–å·¥å…·
    tools = await store.for_store().for_langchain().list_tools_async()
    
    # 3. åˆ›å»º Agent
    llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥è¿›è¡Œæ€è€ƒå’Œæ–‡ä»¶æ“ä½œã€‚"),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])
    
    agent = create_openai_tools_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
    
    return agent_executor

async def main():
    agent_executor = await create_async_agent()
    
    # ä½¿ç”¨ Agent
    response = await agent_executor.ainvoke({
        "input": "å¸®æˆ‘åˆ†æä¸€ä¸‹å½“å‰ç›®å½•çš„æ–‡ä»¶ç»“æ„ï¼Œå¹¶ç»™å‡ºä¼˜åŒ–å»ºè®®"
    })
    print(response["output"])

# è¿è¡Œå¼‚æ­¥ç¤ºä¾‹
asyncio.run(main())
```

## Agent çº§åˆ«é›†æˆç¤ºä¾‹

### å¤š Agent åä½œç³»ç»Ÿ

```python
from mcpstore import MCPStore
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

def create_specialized_agent(store, agent_id, services, system_prompt):
    """åˆ›å»ºä¸“é—¨åŒ–çš„ Agent"""
    
    # ä¸ºç‰¹å®š Agent æ·»åŠ ä¸“å±æœåŠ¡
    agent_context = store.for_agent(agent_id)
    for service in services:
        agent_context.add_service(service)
    
    # è·å– Agent ä¸“å±å·¥å…·
    tools = agent_context.for_langchain().list_tools()
    
    # åˆ›å»º LLM å’Œæç¤º
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])
    
    # åˆ›å»º Agent
    agent = create_openai_tools_agent(llm, tools, prompt)
    return AgentExecutor(agent=agent, tools=tools, verbose=True)

# åˆå§‹åŒ– MCPStore
store = MCPStore.setup_store()

# åˆ›å»ºæ•°æ®åˆ†æ Agent
data_agent = create_specialized_agent(
    store=store,
    agent_id="data_analyst",
    services=[
        {"name": "calculator", "command": "npx", "args": ["-y", "calculator-mcp"]},
        {"name": "filesystem", "command": "npx", "args": ["-y", "filesystem-mcp"]}
    ],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ï¼Œæ“…é•¿è®¡ç®—å’Œæ–‡ä»¶å¤„ç†ã€‚"
)

# åˆ›å»ºå¤©æ°” Agent
weather_agent = create_specialized_agent(
    store=store,
    agent_id="weather_specialist", 
    services=[
        {"name": "weather", "url": "https://weather.example.com/mcp"}
    ],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªå¤©æ°”ä¸“å®¶ï¼Œä¸“é—¨æä¾›å¤©æ°”ä¿¡æ¯å’Œé¢„æŠ¥ã€‚"
)

# ä½¿ç”¨ä¸åŒçš„ Agent
data_response = data_agent.invoke({
    "input": "è®¡ç®— 1+2+3+...+100 çš„å’Œï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶"
})

weather_response = weather_agent.invoke({
    "input": "æŸ¥è¯¢ä¸Šæµ·æ˜å¤©çš„å¤©æ°”"
})

print("æ•°æ®åˆ†æç»“æœ:", data_response["output"])
print("å¤©æ°”æŸ¥è¯¢ç»“æœ:", weather_response["output"])
```

## æ··åˆå·¥å…·é›†æˆç¤ºä¾‹

### MCP å·¥å…· + è‡ªå®šä¹‰å·¥å…·

```python
from mcpstore import MCPStore
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from datetime import date, datetime
import requests

# è‡ªå®šä¹‰ LangChain å·¥å…·
@tool
def get_current_date() -> str:
    """è·å–å½“å‰æ—¥æœŸ"""
    return date.today().isoformat()

@tool
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´"""
    return datetime.now().strftime("%H:%M:%S")

@tool
def calculate_age(birth_year: int) -> str:
    """æ ¹æ®å‡ºç”Ÿå¹´ä»½è®¡ç®—å¹´é¾„"""
    current_year = date.today().year
    age = current_year - birth_year
    return f"å¹´é¾„å¤§çº¦æ˜¯ {age} å²"

@tool
def get_exchange_rate(from_currency: str, to_currency: str) -> str:
    """è·å–æ±‡ç‡ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    # è¿™é‡Œæ˜¯æ¨¡æ‹Ÿå®ç°ï¼Œå®é™…åº”è¯¥è°ƒç”¨çœŸå®çš„æ±‡ç‡API
    rates = {
        ("USD", "CNY"): 7.2,
        ("EUR", "CNY"): 7.8,
        ("GBP", "CNY"): 9.1
    }
    rate = rates.get((from_currency.upper(), to_currency.upper()), 1.0)
    return f"1 {from_currency} = {rate} {to_currency}"

# è·å– MCP å·¥å…·
store = MCPStore.setup_store()
store.for_store().add_service()  # æ³¨å†Œæ‰€æœ‰é…ç½®çš„æœåŠ¡
mcp_tools = store.for_store().for_langchain().list_tools()

# åˆå¹¶æ‰€æœ‰å·¥å…·
all_tools = mcp_tools + [
    get_current_date, 
    get_current_time, 
    calculate_age, 
    get_exchange_rate
]

print(f"ğŸ”§ å·¥å…·æ€»æ•°: {len(all_tools)}")
print(f"  MCPå·¥å…·: {len(mcp_tools)} ä¸ª")
print(f"  è‡ªå®šä¹‰å·¥å…·: {len(all_tools) - len(mcp_tools)} ä¸ª")

# åˆ›å»ºå¢å¼ºçš„ Agent
llm = ChatOpenAI(model="gpt-4", temperature=0)

prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªå…¨èƒ½åŠ©æ‰‹ï¼Œæ‹¥æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š
    1. MCPå·¥å…·ï¼šå¯ä»¥è®¿é—®å„ç§å¤–éƒ¨æœåŠ¡
    2. æ—¶é—´å·¥å…·ï¼šè·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´
    3. è®¡ç®—å·¥å…·ï¼šè¿›è¡Œå¹´é¾„è®¡ç®—
    4. æ±‡ç‡å·¥å…·ï¼šæŸ¥è¯¢è´§å¸æ±‡ç‡
    
    è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚"""),
    ("user", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

agent = create_openai_tools_agent(llm, all_tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=all_tools, verbose=True)

# æµ‹è¯•æ··åˆå·¥å…·ä½¿ç”¨
test_queries = [
    "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿä»Šå¤©æ˜¯å‡ å·ï¼Ÿ",
    "æˆ‘1990å¹´å‡ºç”Ÿï¼Œä»Šå¹´å¤šå¤§äº†ï¼Ÿ",
    "1ç¾å…ƒç­‰äºå¤šå°‘äººæ°‘å¸ï¼Ÿ",
    "å¸®æˆ‘æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åå‘Šè¯‰æˆ‘ç°åœ¨çš„æ—¶é—´"
]

for query in test_queries:
    print(f"\nğŸ¤” ç”¨æˆ·é—®é¢˜: {query}")
    response = agent_executor.invoke({"input": query})
    print(f"ğŸ¤– åŠ©æ‰‹å›ç­”: {response['output']}")
    print("-" * 50)
```

## é“¾å¼è°ƒç”¨é›†æˆç¤ºä¾‹

### æœåŠ¡æ³¨å†Œ â†’ å·¥å…·è½¬æ¢ â†’ Agent åˆ›å»º

```python
from mcpstore import MCPStore
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# ä¸€è¡Œä»£ç å®Œæˆï¼šæœåŠ¡æ³¨å†Œ â†’ å·¥å…·è½¬æ¢
tools = (
    MCPStore.setup_store()
    .for_store()
    .add_service({
        "name": "comprehensive-service",
        "url": "https://api.example.com/mcp"
    })
    .add_service({
        "name": "local-tools",
        "command": "npx",
        "args": ["-y", "local-tools-mcp"]
    })
    .for_langchain()
    .list_tools()
)

print(f"ğŸš€ é“¾å¼è°ƒç”¨è·å¾— {len(tools)} ä¸ªå·¥å…·")

# å¿«é€Ÿåˆ›å»º Agent
llm = ChatOpenAI(model="gpt-3.5-turbo")

prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å¤šç§å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ã€‚"),
    ("user", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

agent_executor = AgentExecutor(
    agent=create_openai_tools_agent(llm, tools, prompt),
    tools=tools,
    verbose=True
)

# ä½¿ç”¨ Agent
response = agent_executor.invoke({
    "input": "å¸®æˆ‘å®Œæˆä¸€ä¸ªå¤æ‚çš„ä»»åŠ¡ï¼Œéœ€è¦ä½¿ç”¨å¤šä¸ªå·¥å…·"
})
print(response["output"])
```

## é”™è¯¯å¤„ç†å’Œé‡è¯•ç¤ºä¾‹

### å¸¦é”™è¯¯å¤„ç†çš„ Agent

```python
from mcpstore import MCPStore
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_robust_agent():
    """åˆ›å»ºå¸¦é”™è¯¯å¤„ç†çš„å¥å£® Agent"""
    
    try:
        # åˆå§‹åŒ– MCPStore
        store = MCPStore.setup_store()
        
        # å°è¯•æ·»åŠ æœåŠ¡
        services_to_add = [
            {"name": "weather", "url": "https://weather.example.com/mcp"},
            {"name": "calculator", "command": "npx", "args": ["-y", "calculator-mcp"]},
            {"name": "filesystem", "command": "npx", "args": ["-y", "filesystem-mcp"]}
        ]
        
        successful_services = []
        for service in services_to_add:
            try:
                store.for_store().add_service(service)
                successful_services.append(service["name"])
                logger.info(f"âœ… æˆåŠŸæ·»åŠ æœåŠ¡: {service['name']}")
            except Exception as e:
                logger.error(f"âŒ æ·»åŠ æœåŠ¡å¤±è´¥ {service['name']}: {e}")
        
        # è·å–å·¥å…·
        tools = store.for_store().for_langchain().list_tools()
        
        if not tools:
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„å·¥å…·ï¼Œåˆ›å»ºåŸºç¡€ Agent")
            return None
        
        logger.info(f"ğŸ› ï¸ æˆåŠŸè·å– {len(tools)} ä¸ªå·¥å…·")
        
        # åˆ›å»º Agent
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå½“å‰å¯ç”¨çš„æœåŠ¡æœ‰ï¼š{successful_services}
            å¦‚æœæŸä¸ªå·¥å…·ä¸å¯ç”¨ï¼Œè¯·å‘ŠçŸ¥ç”¨æˆ·å¹¶æä¾›æ›¿ä»£æ–¹æ¡ˆã€‚"""),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        agent = create_openai_tools_agent(llm, tools, prompt)
        agent_executor = AgentExecutor(
            agent=agent, 
            tools=tools, 
            verbose=True,
            handle_parsing_errors=True,  # å¤„ç†è§£æé”™è¯¯
            max_iterations=5  # é™åˆ¶æœ€å¤§è¿­ä»£æ¬¡æ•°
        )
        
        return agent_executor
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»º Agent å¤±è´¥: {e}")
        return None

def safe_agent_invoke(agent_executor, query, max_retries=3):
    """å®‰å…¨çš„ Agent è°ƒç”¨ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    
    for attempt in range(max_retries):
        try:
            logger.info(f"ğŸ”„ å°è¯• {attempt + 1}/{max_retries}: {query}")
            response = agent_executor.invoke({"input": query})
            logger.info(f"âœ… è°ƒç”¨æˆåŠŸ")
            return response["output"]
            
        except Exception as e:
            logger.error(f"âŒ è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                logger.info("â³ ç­‰å¾…é‡è¯•...")
                import time
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                logger.error("âŒ æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")
                return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ï¼š{e}"

# ä½¿ç”¨ç¤ºä¾‹
agent_executor = create_robust_agent()

if agent_executor:
    queries = [
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "è®¡ç®— 123 + 456",
        "åˆ—å‡ºå½“å‰ç›®å½•çš„æ–‡ä»¶"
    ]
    
    for query in queries:
        print(f"\nğŸ¤” ç”¨æˆ·é—®é¢˜: {query}")
        result = safe_agent_invoke(agent_executor, query)
        print(f"ğŸ¤– åŠ©æ‰‹å›ç­”: {result}")
        print("-" * 50)
else:
    print("âŒ æ— æ³•åˆ›å»º Agentï¼Œè¯·æ£€æŸ¥æœåŠ¡é…ç½®")
```

## æ³¨æ„äº‹é¡¹

1. **æœåŠ¡å¯ç”¨æ€§**: ç¡®ä¿ MCP æœåŠ¡æ­£å¸¸è¿è¡Œ
2. **API å¯†é’¥**: é…ç½®å¿…è¦çš„ API å¯†é’¥ï¼ˆå¦‚ OpenAIï¼‰
3. **é”™è¯¯å¤„ç†**: å®ç°é€‚å½“çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
4. **å·¥å…·é€‰æ‹©**: LLM ä¼šè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·ï¼Œä½†å¯èƒ½éœ€è¦æ˜ç¡®çš„æŒ‡å¯¼
5. **æ€§èƒ½è€ƒè™‘**: å¤§é‡å·¥å…·å¯èƒ½å½±å“ LLM çš„é€‰æ‹©æ•ˆç‡

## ç›¸å…³æ–‡æ¡£

- [for_langchain().list_tools()](as-langchain-tools.md) - LangChain å·¥å…·è½¬æ¢
- [call_tool()](../usage/call-tool.md) - ç›´æ¥å·¥å…·è°ƒç”¨
- [add_service()](../../services/registration/register-service.md) - æœåŠ¡æ³¨å†Œ

## ä¸‹ä¸€æ­¥

- äº†è§£ [å·¥å…·ç›´æ¥è°ƒç”¨](../usage/call-tool.md)
- å­¦ä¹  [æœåŠ¡æ³¨å†Œæ–¹æ³•](../../services/registration/register-service.md)
- æŸ¥çœ‹ [é«˜çº§å¼€å‘æŒ‡å—](../../advanced/concepts.md)
