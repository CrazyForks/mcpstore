# å®Œæ•´ç¤ºä¾‹é›†åˆ

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›äº† MCPStore çš„å®Œæ•´ä½¿ç”¨ç¤ºä¾‹ï¼Œæ¶µç›–ä»åŸºç¡€æ“ä½œåˆ°é«˜çº§åŠŸèƒ½çš„å„ç§åœºæ™¯ã€‚è¿™äº›ç¤ºä¾‹å¯ä»¥å¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹å¹¶æŒæ¡ MCPStore çš„å„ç§åŠŸèƒ½ã€‚

## ğŸš€ åŸºç¡€ç¤ºä¾‹

### ç¤ºä¾‹1: å¿«é€Ÿå¼€å§‹

```python
from mcpstore import MCPStore

# 1. åˆå§‹åŒ– MCPStore
store = MCPStore()

# 2. æ·»åŠ æ–‡ä»¶ç³»ç»ŸæœåŠ¡
store.add_service({
    "mcpServers": {
        "filesystem": {
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"]
        }
    }
})

# 3. åˆ—å‡ºå¯ç”¨å·¥å…·
tools = store.list_tools()
print(f"ğŸ“‹ å¯ç”¨å·¥å…·: {len(tools)} ä¸ª")
for tool in tools[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
    print(f"  - {tool['name']}: {tool.get('description', 'æ— æè¿°')}")

# 4. è°ƒç”¨å·¥å…·
result = store.call_tool("list_directory", {"path": "/tmp"})
print(f"ğŸ“ ç›®å½•å†…å®¹: {result}")

# 5. ä½¿ç”¨ä¾¿æ·æ–¹æ³•
content = store.use_tool("read_file", path="/tmp/test.txt")
print(f"ğŸ“„ æ–‡ä»¶å†…å®¹: {content}")
```

### ç¤ºä¾‹2: å¤šæœåŠ¡ç®¡ç†

```python
from mcpstore import MCPStore

# åˆå§‹åŒ– MCPStore
store = MCPStore()

# æ·»åŠ å¤šä¸ªæœåŠ¡
services_config = {
    "mcpServers": {
        "filesystem": {
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"]
        },
        "web_search": {
            "command": "python",
            "args": ["-m", "web_search_server"]
        },
        "database": {
            "command": "python",
            "args": ["-m", "database_server", "--port", "5432"]
        }
    }
}

store.add_service(services_config)

# æ£€æŸ¥æ‰€æœ‰æœåŠ¡çŠ¶æ€
services = store.list_services()
print("ğŸ” æœåŠ¡çŠ¶æ€æ£€æŸ¥:")
for service in services:
    try:
        status = store.get_service_status(service['name'])
        tools_count = len(store.list_tools(service_name=service['name']))
        print(f"  âœ… {service['name']}: {status} ({tools_count} ä¸ªå·¥å…·)")
    except Exception as e:
        print(f"  âŒ {service['name']}: é”™è¯¯ - {e}")

# æŒ‰æœåŠ¡è°ƒç”¨å·¥å…·
print("\nğŸ› ï¸ å·¥å…·è°ƒç”¨ç¤ºä¾‹:")

# æ–‡ä»¶æ“ä½œ
file_result = store.call_tool("filesystem_write_file", {
    "path": "/tmp/example.txt",
    "content": "Hello MCPStore!"
})
print(f"ğŸ“ æ–‡ä»¶å†™å…¥: {file_result.get('success', False)}")

# Webæœç´¢
search_result = store.call_tool("web_search_search", {
    "query": "MCPStore documentation"
})
print(f"ğŸ” æœç´¢ç»“æœ: {len(search_result.get('results', []))} æ¡")

# æ•°æ®åº“æŸ¥è¯¢
db_result = store.call_tool("database_query", {
    "sql": "SELECT COUNT(*) FROM users"
})
print(f"ğŸ’¾ æ•°æ®åº“æŸ¥è¯¢: {db_result}")
```

## ğŸ”„ æ‰¹é‡æ“ä½œç¤ºä¾‹

### ç¤ºä¾‹3: æ‰¹é‡æ–‡ä»¶å¤„ç†

```python
from mcpstore import MCPStore
import time

store = MCPStore()
store.add_service({
    "mcpServers": {
        "filesystem": {
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"]
        }
    }
})

# æ‰¹é‡åˆ›å»ºæ–‡ä»¶
def batch_file_creation_example():
    """æ‰¹é‡æ–‡ä»¶åˆ›å»ºç¤ºä¾‹"""
    print("ğŸ“ æ‰¹é‡æ–‡ä»¶åˆ›å»ºç¤ºä¾‹")
    
    # å‡†å¤‡æ‰¹é‡è°ƒç”¨
    batch_calls = []
    for i in range(10):
        batch_calls.append({
            "tool_name": "write_file",
            "arguments": {
                "path": f"/tmp/batch_file_{i}.txt",
                "content": f"è¿™æ˜¯æ‰¹é‡åˆ›å»ºçš„æ–‡ä»¶ {i}"
            }
        })
    
    # æ‰§è¡Œæ‰¹é‡è°ƒç”¨
    start_time = time.time()
    results = store.batch_call(batch_calls)
    execution_time = time.time() - start_time
    
    # ç»Ÿè®¡ç»“æœ
    successful = sum(1 for r in results if r.get('success'))
    print(f"âœ… æ‰¹é‡åˆ›å»ºå®Œæˆ: {successful}/{len(results)} æˆåŠŸ")
    print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}s")
    
    return results

# æ‰¹é‡è¯»å–å’Œå¤„ç†
def batch_file_processing_example():
    """æ‰¹é‡æ–‡ä»¶å¤„ç†ç¤ºä¾‹"""
    print("\nğŸ“– æ‰¹é‡æ–‡ä»¶å¤„ç†ç¤ºä¾‹")
    
    # é¦–å…ˆåˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
    dir_result = store.call_tool("list_directory", {"path": "/tmp"})
    files = [f for f in dir_result.get('files', []) if f.startswith('batch_file_')]
    
    # æ‰¹é‡è¯»å–æ–‡ä»¶
    read_calls = []
    for filename in files[:5]:  # åªå¤„ç†å‰5ä¸ªæ–‡ä»¶
        read_calls.append({
            "tool_name": "read_file",
            "arguments": {"path": f"/tmp/{filename}"}
        })
    
    # æ‰§è¡Œæ‰¹é‡è¯»å–
    read_results = store.batch_call(read_calls)
    
    # å¤„ç†è¯»å–ç»“æœ
    total_content_length = 0
    for i, result in enumerate(read_results):
        if result.get('success'):
            content = result.get('content', '')
            total_content_length += len(content)
            print(f"  ğŸ“„ æ–‡ä»¶ {i+1}: {len(content)} å­—ç¬¦")
    
    print(f"ğŸ“Š æ€»å†…å®¹é•¿åº¦: {total_content_length} å­—ç¬¦")

# æ‰§è¡Œç¤ºä¾‹
batch_file_creation_example()
batch_file_processing_example()
```

### ç¤ºä¾‹4: æ··åˆæœåŠ¡æ‰¹é‡è°ƒç”¨

```python
def mixed_service_batch_example():
    """æ··åˆæœåŠ¡æ‰¹é‡è°ƒç”¨ç¤ºä¾‹"""
    print("ğŸ”€ æ··åˆæœåŠ¡æ‰¹é‡è°ƒç”¨ç¤ºä¾‹")
    
    # å‡†å¤‡æ··åˆè°ƒç”¨
    mixed_calls = [
        # æ–‡ä»¶æ“ä½œ
        {
            "tool_name": "write_file",
            "arguments": {
                "path": "/tmp/report.txt",
                "content": "Daily Report\n============\n"
            }
        },
        # Webæœç´¢
        {
            "tool_name": "web_search",
            "arguments": {"query": "MCPStore latest news"}
        },
        # æ•°æ®åº“æŸ¥è¯¢
        {
            "tool_name": "database_query",
            "arguments": {"sql": "SELECT COUNT(*) as user_count FROM users"}
        },
        # æ–‡ä»¶è¯»å–
        {
            "tool_name": "read_file",
            "arguments": {"path": "/tmp/report.txt"}
        }
    ]
    
    # æ‰§è¡Œæ··åˆæ‰¹é‡è°ƒç”¨
    start_time = time.time()
    results = store.batch_call(mixed_calls, parallel=True)
    execution_time = time.time() - start_time
    
    # å¤„ç†ç»“æœ
    print(f"âš¡ æ··åˆè°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}s")
    
    for i, result in enumerate(results):
        call = mixed_calls[i]
        if result.get('success'):
            print(f"  âœ… {call['tool_name']}: æˆåŠŸ")
        else:
            print(f"  âŒ {call['tool_name']}: å¤±è´¥ - {result.get('error')}")

# æ‰§è¡Œæ··åˆæœåŠ¡ç¤ºä¾‹
mixed_service_batch_example()
```

## ğŸ”— é“¾å¼è°ƒç”¨ç¤ºä¾‹

### ç¤ºä¾‹5: æ–‡ä»¶å¤„ç†å·¥ä½œæµ

```python
from mcpstore.chaining import ToolChain

def file_workflow_example():
    """æ–‡ä»¶å¤„ç†å·¥ä½œæµç¤ºä¾‹"""
    print("ğŸ”„ æ–‡ä»¶å¤„ç†å·¥ä½œæµç¤ºä¾‹")
    
    # åˆ›å»ºå·¥å…·é“¾
    chain = ToolChain(store)
    
    # æ„å»ºå·¥ä½œæµ
    chain.add_step(
        "create_directory",
        arguments={"path": "/tmp/workflow_demo"}
    ).add_step(
        "write_file",
        arguments=lambda ctx: {
            "path": "/tmp/workflow_demo/input.txt",
            "content": "Original content for processing"
        }
    ).add_step(
        "read_file",
        arguments={"path": "/tmp/workflow_demo/input.txt"},
        transform=lambda result, ctx: {
            **result,
            "processed_content": result.get('content', '').upper()
        }
    ).add_step(
        "write_file",
        arguments=lambda ctx: {
            "path": "/tmp/workflow_demo/output.txt", 
            "content": ctx['last_result']['processed_content']
        }
    ).add_step(
        "list_directory",
        arguments={"path": "/tmp/workflow_demo"}
    )
    
    # æ‰§è¡Œå·¥ä½œæµ
    try:
        results = chain.execute()
        print(f"âœ… å·¥ä½œæµå®Œæˆï¼Œå…± {len(results)} ä¸ªæ­¥éª¤")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        final_result = results[-1]
        if final_result.get('success'):
            files = final_result.get('files', [])
            print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶: {files}")
        
    except Exception as e:
        print(f"âŒ å·¥ä½œæµå¤±è´¥: {e}")

file_workflow_example()
```

### ç¤ºä¾‹6: æ•°æ®å¤„ç†ç®¡é“

```python
from mcpstore.chaining import Pipeline

def data_processing_pipeline_example():
    """æ•°æ®å¤„ç†ç®¡é“ç¤ºä¾‹"""
    print("\nğŸ”§ æ•°æ®å¤„ç†ç®¡é“ç¤ºä¾‹")
    
    # å®šä¹‰å¤„ç†å™¨å‡½æ•°
    def fetch_data(store, context):
        """è·å–æ•°æ®"""
        result = store.call_tool("database_query", {
            "sql": "SELECT name, email FROM users LIMIT 10"
        })
        
        return {
            **context,
            "raw_data": result.get('rows', []),
            "record_count": len(result.get('rows', []))
        }
    
    def validate_data(store, context):
        """éªŒè¯æ•°æ®"""
        raw_data = context['raw_data']
        valid_records = []
        
        for record in raw_data:
            if record.get('email') and '@' in record['email']:
                valid_records.append(record)
        
        return {
            **context,
            "valid_data": valid_records,
            "validation_rate": len(valid_records) / len(raw_data) * 100
        }
    
    def save_processed_data(store, context):
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        valid_data = context['valid_data']
        
        # è½¬æ¢ä¸ºCSVæ ¼å¼
        csv_content = "name,email\n"
        for record in valid_data:
            csv_content += f"{record['name']},{record['email']}\n"
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        result = store.call_tool("write_file", {
            "path": "/tmp/processed_users.csv",
            "content": csv_content
        })
        
        return {
            **context,
            "output_file": "/tmp/processed_users.csv",
            "save_success": result.get('success', False)
        }
    
    # åˆ›å»ºç®¡é“
    pipeline = Pipeline(store)
    pipeline.add_processor(fetch_data) \
            .add_processor(validate_data) \
            .add_processor(save_processed_data)
    
    # æ‰§è¡Œç®¡é“
    try:
        initial_context = {"pipeline_id": "data_processing_001"}
        final_result = pipeline.process(initial_context)
        
        print(f"ğŸ“Š æ•°æ®å¤„ç†å®Œæˆ:")
        print(f"  åŸå§‹è®°å½•: {final_result['record_count']}")
        print(f"  æœ‰æ•ˆè®°å½•: {len(final_result['valid_data'])}")
        print(f"  éªŒè¯ç‡: {final_result['validation_rate']:.1f}%")
        print(f"  è¾“å‡ºæ–‡ä»¶: {final_result['output_file']}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")

data_processing_pipeline_example()
```

## ğŸ”§ é«˜çº§åŠŸèƒ½ç¤ºä¾‹

### ç¤ºä¾‹7: ç›‘æ§å’Œæ€§èƒ½åˆ†æ

```python
from mcpstore.monitoring import MonitoringDashboard
from mcpstore.performance import PerformanceBenchmark

def monitoring_example():
    """ç›‘æ§å’Œæ€§èƒ½åˆ†æç¤ºä¾‹"""
    print("ğŸ“Š ç›‘æ§å’Œæ€§èƒ½åˆ†æç¤ºä¾‹")
    
    # å¯åŠ¨ç›‘æ§
    dashboard = MonitoringDashboard(store)
    dashboard.start_monitoring(interval=5)
    
    # æ‰§è¡Œä¸€äº›æ“ä½œæ¥ç”Ÿæˆç›‘æ§æ•°æ®
    print("ğŸ”„ æ‰§è¡Œæ“ä½œç”Ÿæˆç›‘æ§æ•°æ®...")
    
    for i in range(20):
        try:
            # éšæœºé€‰æ‹©æ“ä½œ
            import random
            operations = [
                lambda: store.call_tool("list_directory", {"path": "/tmp"}),
                lambda: store.call_tool("read_file", {"path": "/tmp/test.txt"}),
                lambda: store.call_tool("write_file", {
                    "path": f"/tmp/monitor_test_{i}.txt",
                    "content": f"Monitor test {i}"
                })
            ]
            
            operation = random.choice(operations)
            operation()
            
            time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿ
            
        except Exception as e:
            print(f"âš ï¸ æ“ä½œ {i} å¤±è´¥: {e}")
    
    # ç­‰å¾…ä¸€æ®µæ—¶é—´æ”¶é›†æ•°æ®
    time.sleep(10)
    
    # æ˜¾ç¤ºç›‘æ§ä»ªè¡¨æ¿
    dashboard.print_dashboard()
    
    # åœæ­¢ç›‘æ§
    dashboard.stop_monitoring()
    
    # æ€§èƒ½åŸºå‡†æµ‹è¯•
    print("\nğŸƒ æ€§èƒ½åŸºå‡†æµ‹è¯•:")
    benchmark = PerformanceBenchmark(store)
    
    # æµ‹è¯•ç®€å•è°ƒç”¨
    def simple_call_test():
        store.call_tool("list_directory", {"path": "/tmp"})
    
    # æµ‹è¯•æ‰¹é‡è°ƒç”¨
    def batch_call_test():
        calls = [
            {"tool_name": "list_directory", "arguments": {"path": "/tmp"}}
            for _ in range(3)
        ]
        store.batch_call(calls)
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark.run_benchmark("ç®€å•è°ƒç”¨", simple_call_test, iterations=30)
    benchmark.run_benchmark("æ‰¹é‡è°ƒç”¨", batch_call_test, iterations=10)
    
    # æ˜¾ç¤ºç»“æœ
    benchmark.print_results()

monitoring_example()
```

### ç¤ºä¾‹8: é”™è¯¯å¤„ç†å’Œæ¢å¤

```python
from mcpstore.error_handling import RetryManager, RetryConfig, FallbackManager

def error_handling_example():
    """é”™è¯¯å¤„ç†å’Œæ¢å¤ç¤ºä¾‹"""
    print("\nğŸ›¡ï¸ é”™è¯¯å¤„ç†å’Œæ¢å¤ç¤ºä¾‹")
    
    # é…ç½®é‡è¯•æœºåˆ¶
    retry_config = RetryConfig(
        max_attempts=3,
        strategy=RetryStrategy.EXPONENTIAL,
        base_delay=1.0,
        exceptions=(Exception,)
    )
    
    retry_manager = RetryManager(retry_config)
    
    # æ¨¡æ‹Ÿå¯èƒ½å¤±è´¥çš„æ“ä½œ
    def unreliable_operation():
        """ä¸å¯é çš„æ“ä½œï¼ˆæœ‰æ—¶ä¼šå¤±è´¥ï¼‰"""
        import random
        if random.random() < 0.7:  # 70% å¤±è´¥ç‡
            raise Exception("æ¨¡æ‹Ÿçš„ç½‘ç»œé”™è¯¯")
        
        return store.call_tool("list_directory", {"path": "/tmp"})
    
    # ä½¿ç”¨é‡è¯•æœºåˆ¶
    try:
        print("ğŸ”„ å°è¯•ä¸å¯é æ“ä½œï¼ˆå¸¦é‡è¯•ï¼‰...")
        result = retry_manager.execute(unreliable_operation)
        print(f"âœ… æ“ä½œæˆåŠŸ: {len(result.get('files', []))} ä¸ªæ–‡ä»¶")
    except Exception as e:
        print(f"âŒ æ“ä½œæœ€ç»ˆå¤±è´¥: {e}")
    
    # é…ç½®é™çº§æœºåˆ¶
    fallback_manager = FallbackManager()
    
    # æ·»åŠ ç¼“å­˜é™çº§ç­–ç•¥
    from mcpstore.error_handling import CacheFallback, DefaultValueFallback
    
    fallback_manager.add_strategy(CacheFallback(cache_duration=300))
    fallback_manager.add_strategy(DefaultValueFallback({"files": [], "fallback": True}))
    
    # ä½¿ç”¨é™çº§æœºåˆ¶
    def get_directory_listing():
        """è·å–ç›®å½•åˆ—è¡¨ï¼ˆå¯èƒ½å¤±è´¥ï¼‰"""
        # æ¨¡æ‹ŸæœåŠ¡ä¸å¯ç”¨
        raise Exception("æœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
    
    try:
        print("\nğŸ”„ å°è¯•è·å–ç›®å½•åˆ—è¡¨ï¼ˆå¸¦é™çº§ï¼‰...")
        result = fallback_manager.execute_with_fallback(get_directory_listing)
        
        if result.get('fallback'):
            print("ğŸ“¦ ä½¿ç”¨äº†é™çº§ç­–ç•¥")
        else:
            print(f"âœ… æ­£å¸¸è·å–: {len(result.get('files', []))} ä¸ªæ–‡ä»¶")
            
    except Exception as e:
        print(f"âŒ æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥: {e}")

error_handling_example()
```

## ğŸ¯ å®é™…åº”ç”¨åœºæ™¯

### ç¤ºä¾‹9: è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆ

```python
def automated_report_example():
    """è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆç¤ºä¾‹"""
    print("ğŸ“‹ è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆç¤ºä¾‹")
    
    from datetime import datetime
    
    # æŠ¥å‘Šç”Ÿæˆå·¥ä½œæµ
    def generate_daily_report():
        """ç”Ÿæˆæ—¥å¸¸æŠ¥å‘Š"""
        
        # 1. æ”¶é›†ç³»ç»Ÿä¿¡æ¯
        system_info = store.call_tool("get_system_info", {})
        
        # 2. æŸ¥è¯¢æ•°æ®åº“ç»Ÿè®¡
        db_stats = store.call_tool("database_query", {
            "sql": "SELECT COUNT(*) as total_users, MAX(created_at) as last_signup FROM users"
        })
        
        # 3. æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä½¿ç”¨æƒ…å†µ
        disk_usage = store.call_tool("get_disk_usage", {"path": "/tmp"})
        
        # 4. ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = f"""
æ—¥å¸¸ç³»ç»ŸæŠ¥å‘Š
=============
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ç³»ç»Ÿä¿¡æ¯:
- CPUä½¿ç”¨ç‡: {system_info.get('cpu_percent', 'N/A')}%
- å†…å­˜ä½¿ç”¨ç‡: {system_info.get('memory_percent', 'N/A')}%

æ•°æ®åº“ç»Ÿè®¡:
- æ€»ç”¨æˆ·æ•°: {db_stats.get('total_users', 'N/A')}
- æœ€åæ³¨å†Œ: {db_stats.get('last_signup', 'N/A')}

ç£ç›˜ä½¿ç”¨:
- å·²ç”¨ç©ºé—´: {disk_usage.get('used_gb', 'N/A')} GB
- å¯ç”¨ç©ºé—´: {disk_usage.get('free_gb', 'N/A')} GB

æŠ¥å‘Šç”Ÿæˆå®Œæˆã€‚
"""
        
        # 5. ä¿å­˜æŠ¥å‘Š
        report_filename = f"/tmp/daily_report_{datetime.now().strftime('%Y%m%d')}.txt"
        save_result = store.call_tool("write_file", {
            "path": report_filename,
            "content": report_content
        })
        
        if save_result.get('success'):
            print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
            
            # 6. å¯é€‰ï¼šå‘é€é‚®ä»¶é€šçŸ¥
            # email_result = store.call_tool("send_email", {
            #     "to": "admin@example.com",
            #     "subject": "æ—¥å¸¸ç³»ç»ŸæŠ¥å‘Š",
            #     "body": "è¯·æŸ¥çœ‹é™„ä»¶ä¸­çš„ç³»ç»ŸæŠ¥å‘Š",
            #     "attachment": report_filename
            # })
            
        return report_filename
    
    # æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆ
    try:
        report_file = generate_daily_report()
        print(f"ğŸ“Š æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_file}")
    except Exception as e:
        print(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

automated_report_example()
```

### ç¤ºä¾‹10: æ–‡ä»¶åŒæ­¥ç³»ç»Ÿ

```python
def file_sync_example():
    """æ–‡ä»¶åŒæ­¥ç³»ç»Ÿç¤ºä¾‹"""
    print("\nğŸ”„ æ–‡ä»¶åŒæ­¥ç³»ç»Ÿç¤ºä¾‹")
    
    def sync_directories(source_dir, target_dir):
        """åŒæ­¥ç›®å½•"""
        
        # 1. è·å–æºç›®å½•æ–‡ä»¶åˆ—è¡¨
        source_files = store.call_tool("list_directory", {"path": source_dir})
        
        # 2. è·å–ç›®æ ‡ç›®å½•æ–‡ä»¶åˆ—è¡¨
        target_files = store.call_tool("list_directory", {"path": target_dir})
        
        source_file_names = set(source_files.get('files', []))
        target_file_names = set(target_files.get('files', []))
        
        # 3. æ‰¾å‡ºéœ€è¦åŒæ­¥çš„æ–‡ä»¶
        files_to_copy = source_file_names - target_file_names
        files_to_delete = target_file_names - source_file_names
        
        print(f"ğŸ“ åŒæ­¥åˆ†æ:")
        print(f"  éœ€è¦å¤åˆ¶: {len(files_to_copy)} ä¸ªæ–‡ä»¶")
        print(f"  éœ€è¦åˆ é™¤: {len(files_to_delete)} ä¸ªæ–‡ä»¶")
        
        # 4. æ‰¹é‡å¤åˆ¶æ–‡ä»¶
        if files_to_copy:
            copy_calls = []
            for filename in files_to_copy:
                # è¯»å–æºæ–‡ä»¶
                copy_calls.append({
                    "tool_name": "read_file",
                    "arguments": {"path": f"{source_dir}/{filename}"}
                })
            
            # æ‰¹é‡è¯»å–
            read_results = store.batch_call(copy_calls)
            
            # æ‰¹é‡å†™å…¥
            write_calls = []
            for i, filename in enumerate(files_to_copy):
                read_result = read_results[i]
                if read_result.get('success'):
                    write_calls.append({
                        "tool_name": "write_file",
                        "arguments": {
                            "path": f"{target_dir}/{filename}",
                            "content": read_result.get('content', '')
                        }
                    })
            
            if write_calls:
                write_results = store.batch_call(write_calls)
                successful_copies = sum(1 for r in write_results if r.get('success'))
                print(f"âœ… æˆåŠŸå¤åˆ¶: {successful_copies}/{len(write_calls)} ä¸ªæ–‡ä»¶")
        
        # 5. æ‰¹é‡åˆ é™¤æ–‡ä»¶
        if files_to_delete:
            delete_calls = []
            for filename in files_to_delete:
                delete_calls.append({
                    "tool_name": "delete_file",
                    "arguments": {"path": f"{target_dir}/{filename}"}
                })
            
            delete_results = store.batch_call(delete_calls)
            successful_deletes = sum(1 for r in delete_results if r.get('success'))
            print(f"ğŸ—‘ï¸ æˆåŠŸåˆ é™¤: {successful_deletes}/{len(delete_calls)} ä¸ªæ–‡ä»¶")
        
        print("ğŸ¯ ç›®å½•åŒæ­¥å®Œæˆ")
    
    # æ‰§è¡ŒåŒæ­¥
    try:
        sync_directories("/tmp/source", "/tmp/backup")
    except Exception as e:
        print(f"âŒ åŒæ­¥å¤±è´¥: {e}")

file_sync_example()
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹](../getting-started/quick-demo.md)
- [æœåŠ¡ç®¡ç†](../services/management/service-management.md)
- [å·¥å…·è°ƒç”¨](../tools/usage/call-tool.md)
- [æ‰¹é‡è°ƒç”¨](../tools/usage/batch-call.md)
- [é“¾å¼è°ƒç”¨](../advanced/chaining.md)
- [ç›‘æ§ç³»ç»Ÿ](../advanced/monitoring.md)
- [é”™è¯¯å¤„ç†](../advanced/error-handling.md)

## ğŸ“š æœ€ä½³å®è·µæ€»ç»“

1. **æœåŠ¡ç®¡ç†**ï¼šåˆç†é…ç½®æœåŠ¡ï¼Œå®šæœŸæ£€æŸ¥æœåŠ¡çŠ¶æ€
2. **é”™è¯¯å¤„ç†**ï¼šå®ç°å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
3. **æ€§èƒ½ä¼˜åŒ–**ï¼šä½¿ç”¨æ‰¹é‡è°ƒç”¨å’Œé“¾å¼è°ƒç”¨æé«˜æ•ˆç‡
4. **ç›‘æ§åˆ†æ**ï¼šå»ºç«‹ç›‘æ§ä½“ç³»ï¼Œåˆ†æä½¿ç”¨æ¨¡å¼
5. **èµ„æºç®¡ç†**ï¼šåŠæ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œèµ„æº
6. **å®‰å…¨è€ƒè™‘**ï¼šéªŒè¯è¾“å…¥å‚æ•°ï¼Œæ§åˆ¶è®¿é—®æƒé™

---

**æ›´æ–°æ—¶é—´**: 2025-01-09  
**ç‰ˆæœ¬**: 1.0.0
