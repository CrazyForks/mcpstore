# æ€§èƒ½ä¼˜åŒ–æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

MCPStore çš„æ€§èƒ½ä¼˜åŒ–æ¶µç›–æœåŠ¡å¯åŠ¨ã€å·¥å…·è°ƒç”¨ã€è¿æ¥ç®¡ç†ã€å†…å­˜ä½¿ç”¨ç­‰å¤šä¸ªæ–¹é¢ã€‚é€šè¿‡åˆç†çš„é…ç½®å’Œä¼˜åŒ–ç­–ç•¥ï¼Œå¯ä»¥æ˜¾è‘—æå‡ç³»ç»Ÿçš„å“åº”é€Ÿåº¦å’Œååé‡ã€‚

## ğŸ—ï¸ æ€§èƒ½ä¼˜åŒ–æ¶æ„

```mermaid
graph TB
    A[æ€§èƒ½ä¼˜åŒ–] --> B[è¿æ¥ä¼˜åŒ–]
    A --> C[è°ƒç”¨ä¼˜åŒ–]
    A --> D[å†…å­˜ä¼˜åŒ–]
    A --> E[å¹¶å‘ä¼˜åŒ–]
    
    B --> F[è¿æ¥æ± ]
    B --> G[è¿æ¥å¤ç”¨]
    B --> H[è¶…æ—¶é…ç½®]
    
    C --> I[æ‰¹é‡è°ƒç”¨]
    C --> J[å¼‚æ­¥è°ƒç”¨]
    C --> K[ç»“æœç¼“å­˜]
    
    D --> L[å¯¹è±¡æ± ]
    D --> M[åƒåœ¾å›æ”¶]
    D --> N[å†…å­˜ç›‘æ§]
    
    E --> O[çº¿ç¨‹æ± ]
    E --> P[åç¨‹]
    E --> Q[è´Ÿè½½å‡è¡¡]
```

## ğŸš€ è¿æ¥ä¼˜åŒ–

### è¿æ¥æ± é…ç½®

```python
from mcpstore import MCPStore
from mcpstore.config import ConnectionPoolConfig

# è¿æ¥æ± é…ç½®
pool_config = ConnectionPoolConfig(
    # åŸºç¡€é…ç½®
    min_connections=2,      # æœ€å°è¿æ¥æ•°
    max_connections=10,     # æœ€å¤§è¿æ¥æ•°
    max_idle_time=300,      # æœ€å¤§ç©ºé—²æ—¶é—´ï¼ˆç§’ï¼‰
    
    # è¶…æ—¶é…ç½®
    connection_timeout=30,   # è¿æ¥è¶…æ—¶
    read_timeout=60,        # è¯»å–è¶…æ—¶
    write_timeout=30,       # å†™å…¥è¶…æ—¶
    
    # é‡è¯•é…ç½®
    max_retries=3,          # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delay=1.0,        # é‡è¯•å»¶è¿Ÿ
    
    # å¥åº·æ£€æŸ¥
    health_check_interval=60,  # å¥åº·æ£€æŸ¥é—´éš”
    health_check_timeout=5     # å¥åº·æ£€æŸ¥è¶…æ—¶
)

# ä½¿ç”¨è¿æ¥æ± é…ç½®
store = MCPStore(connection_pool_config=pool_config)
```

### è¿æ¥å¤ç”¨ç­–ç•¥

```python
class ConnectionManager:
    """è¿æ¥ç®¡ç†å™¨"""
    
    def __init__(self, store):
        self.store = store
        self.connection_cache = {}
        self.connection_stats = {}
    
    def get_optimized_connection(self, service_name):
        """è·å–ä¼˜åŒ–çš„è¿æ¥"""
        
        # æ£€æŸ¥ç¼“å­˜çš„è¿æ¥
        if service_name in self.connection_cache:
            connection = self.connection_cache[service_name]
            
            # éªŒè¯è¿æ¥æœ‰æ•ˆæ€§
            if self._is_connection_healthy(connection):
                self._update_connection_stats(service_name, "reused")
                return connection
            else:
                # æ¸…ç†æ— æ•ˆè¿æ¥
                del self.connection_cache[service_name]
        
        # åˆ›å»ºæ–°è¿æ¥
        connection = self._create_new_connection(service_name)
        self.connection_cache[service_name] = connection
        self._update_connection_stats(service_name, "created")
        
        return connection
    
    def _is_connection_healthy(self, connection):
        """æ£€æŸ¥è¿æ¥å¥åº·çŠ¶æ€"""
        try:
            # å‘é€å¿ƒè·³æ£€æŸ¥
            response = connection.ping(timeout=2)
            return response.get("status") == "ok"
        except:
            return False
    
    def _create_new_connection(self, service_name):
        """åˆ›å»ºæ–°è¿æ¥"""
        return self.store._get_service_connection(service_name)
    
    def _update_connection_stats(self, service_name, action):
        """æ›´æ–°è¿æ¥ç»Ÿè®¡"""
        if service_name not in self.connection_stats:
            self.connection_stats[service_name] = {
                "created": 0,
                "reused": 0,
                "failed": 0
            }
        
        self.connection_stats[service_name][action] += 1
    
    def get_connection_stats(self):
        """è·å–è¿æ¥ç»Ÿè®¡"""
        return self.connection_stats
    
    def cleanup_idle_connections(self, max_idle_time=300):
        """æ¸…ç†ç©ºé—²è¿æ¥"""
        current_time = time.time()
        to_remove = []
        
        for service_name, connection in self.connection_cache.items():
            if hasattr(connection, 'last_used'):
                if current_time - connection.last_used > max_idle_time:
                    to_remove.append(service_name)
        
        for service_name in to_remove:
            del self.connection_cache[service_name]
            print(f"ğŸ§¹ æ¸…ç†ç©ºé—²è¿æ¥: {service_name}")

# ä½¿ç”¨è¿æ¥ç®¡ç†å™¨
conn_manager = ConnectionManager(store)

# å®šæœŸæ¸…ç†ç©ºé—²è¿æ¥
import threading
def cleanup_worker():
    while True:
        time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        conn_manager.cleanup_idle_connections()

cleanup_thread = threading.Thread(target=cleanup_worker, daemon=True)
cleanup_thread.start()
```

## âš¡ è°ƒç”¨ä¼˜åŒ–

### æ‰¹é‡è°ƒç”¨ä¼˜åŒ–

```python
class OptimizedBatchCaller:
    """ä¼˜åŒ–çš„æ‰¹é‡è°ƒç”¨å™¨"""
    
    def __init__(self, store, batch_size=10, max_workers=5):
        self.store = store
        self.batch_size = batch_size
        self.max_workers = max_workers
        self.call_queue = []
        self.results_cache = {}
    
    def add_call(self, tool_name, arguments, cache_key=None):
        """æ·»åŠ è°ƒç”¨åˆ°é˜Ÿåˆ—"""
        call = {
            "tool_name": tool_name,
            "arguments": arguments,
            "cache_key": cache_key
        }
        self.call_queue.append(call)
    
    def execute_batch(self):
        """æ‰§è¡Œæ‰¹é‡è°ƒç”¨"""
        if not self.call_queue:
            return []
        
        # æ£€æŸ¥ç¼“å­˜
        cached_results = []
        uncached_calls = []
        
        for call in self.call_queue:
            if call["cache_key"] and call["cache_key"] in self.results_cache:
                cached_results.append(self.results_cache[call["cache_key"]])
                print(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜ç»“æœ: {call['tool_name']}")
            else:
                uncached_calls.append(call)
        
        # åˆ†æ‰¹å¤„ç†æœªç¼“å­˜çš„è°ƒç”¨
        batch_results = []
        for i in range(0, len(uncached_calls), self.batch_size):
            batch = uncached_calls[i:i + self.batch_size]
            batch_result = self._execute_batch_chunk(batch)
            batch_results.extend(batch_result)
        
        # æ›´æ–°ç¼“å­˜
        for call, result in zip(uncached_calls, batch_results):
            if call["cache_key"]:
                self.results_cache[call["cache_key"]] = result
        
        # åˆå¹¶ç»“æœ
        all_results = cached_results + batch_results
        
        # æ¸…ç©ºé˜Ÿåˆ—
        self.call_queue = []
        
        return all_results
    
    def _execute_batch_chunk(self, batch):
        """æ‰§è¡Œæ‰¹é‡è°ƒç”¨å—"""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        results = [None] * len(batch)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_index = {}
            for i, call in enumerate(batch):
                future = executor.submit(
                    self.store.call_tool,
                    call["tool_name"],
                    call["arguments"]
                )
                future_to_index[future] = i
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    result = future.result()
                    results[index] = result
                except Exception as e:
                    results[index] = {"error": str(e)}
        
        return results

# ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹é‡è°ƒç”¨
batch_caller = OptimizedBatchCaller(store, batch_size=5, max_workers=3)

# æ·»åŠ å¤šä¸ªè°ƒç”¨
for i in range(20):
    batch_caller.add_call(
        "read_file",
        {"path": f"/tmp/file_{i}.txt"},
        cache_key=f"read_file_{i}"  # ä½¿ç”¨ç¼“å­˜é”®
    )

# æ‰§è¡Œæ‰¹é‡è°ƒç”¨
start_time = time.time()
results = batch_caller.execute_batch()
execution_time = time.time() - start_time

print(f"âš¡ æ‰¹é‡è°ƒç”¨å®Œæˆ: {len(results)} ä¸ªè°ƒç”¨ï¼Œè€—æ—¶ {execution_time:.2f}s")
```

### å¼‚æ­¥è°ƒç”¨ä¼˜åŒ–

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncToolCaller:
    """å¼‚æ­¥å·¥å…·è°ƒç”¨å™¨"""
    
    def __init__(self, store, max_concurrent=10):
        self.store = store
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.executor = ThreadPoolExecutor(max_workers=max_concurrent)
    
    async def call_tool_async(self, tool_name, arguments):
        """å¼‚æ­¥è°ƒç”¨å·¥å…·"""
        async with self.semaphore:
            loop = asyncio.get_event_loop()
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥è°ƒç”¨
            result = await loop.run_in_executor(
                self.executor,
                self.store.call_tool,
                tool_name,
                arguments
            )
            
            return result
    
    async def batch_call_async(self, calls):
        """å¼‚æ­¥æ‰¹é‡è°ƒç”¨"""
        tasks = []
        
        for call in calls:
            task = self.call_tool_async(
                call["tool_name"],
                call["arguments"]
            )
            tasks.append(task)
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                processed_results.append({"error": str(result)})
            else:
                processed_results.append(result)
        
        return processed_results
    
    def close(self):
        """å…³é—­æ‰§è¡Œå™¨"""
        self.executor.shutdown(wait=True)

# ä½¿ç”¨å¼‚æ­¥è°ƒç”¨
async def async_example():
    async_caller = AsyncToolCaller(store, max_concurrent=5)
    
    # å‡†å¤‡è°ƒç”¨åˆ—è¡¨
    calls = [
        {"tool_name": "read_file", "arguments": {"path": f"/tmp/file_{i}.txt"}}
        for i in range(10)
    ]
    
    # å¼‚æ­¥æ‰¹é‡è°ƒç”¨
    start_time = time.time()
    results = await async_caller.batch_call_async(calls)
    execution_time = time.time() - start_time
    
    print(f"ğŸš€ å¼‚æ­¥è°ƒç”¨å®Œæˆ: {len(results)} ä¸ªè°ƒç”¨ï¼Œè€—æ—¶ {execution_time:.2f}s")
    
    async_caller.close()

# è¿è¡Œå¼‚æ­¥ç¤ºä¾‹
# asyncio.run(async_example())
```

## ğŸ’¾ å†…å­˜ä¼˜åŒ–

### å¯¹è±¡æ± ç®¡ç†

```python
from collections import deque
import weakref

class ObjectPool:
    """å¯¹è±¡æ± """
    
    def __init__(self, factory, max_size=100):
        self.factory = factory
        self.max_size = max_size
        self.pool = deque()
        self.active_objects = weakref.WeakSet()
    
    def get_object(self):
        """è·å–å¯¹è±¡"""
        if self.pool:
            obj = self.pool.popleft()
            self._reset_object(obj)
        else:
            obj = self.factory()
        
        self.active_objects.add(obj)
        return obj
    
    def return_object(self, obj):
        """å½’è¿˜å¯¹è±¡"""
        if obj in self.active_objects and len(self.pool) < self.max_size:
            self.pool.append(obj)
    
    def _reset_object(self, obj):
        """é‡ç½®å¯¹è±¡çŠ¶æ€"""
        if hasattr(obj, 'reset'):
            obj.reset()
    
    def get_stats(self):
        """è·å–æ± ç»Ÿè®¡"""
        return {
            "pool_size": len(self.pool),
            "active_objects": len(self.active_objects),
            "max_size": self.max_size
        }

# ç»“æœå¯¹è±¡å·¥å‚
class ToolResult:
    def __init__(self):
        self.reset()
    
    def reset(self):
        self.tool_name = None
        self.arguments = None
        self.result = None
        self.error = None
        self.execution_time = 0

def result_factory():
    return ToolResult()

# ä½¿ç”¨å¯¹è±¡æ± 
result_pool = ObjectPool(result_factory, max_size=50)

def optimized_call_tool(store, tool_name, arguments):
    """ä½¿ç”¨å¯¹è±¡æ± çš„ä¼˜åŒ–è°ƒç”¨"""
    result_obj = result_pool.get_object()
    
    try:
        start_time = time.time()
        
        result_obj.tool_name = tool_name
        result_obj.arguments = arguments
        result_obj.result = store.call_tool(tool_name, arguments)
        result_obj.execution_time = time.time() - start_time
        
        return result_obj
        
    except Exception as e:
        result_obj.error = str(e)
        result_obj.execution_time = time.time() - start_time
        return result_obj
    
    finally:
        # æ³¨æ„ï¼šåœ¨å®é™…ä½¿ç”¨åéœ€è¦æ‰‹åŠ¨å½’è¿˜å¯¹è±¡
        pass

# ä½¿ç”¨ç¤ºä¾‹
result = optimized_call_tool(store, "read_file", {"path": "/tmp/test.txt"})
print(f"è°ƒç”¨ç»“æœ: {result.result}")

# ä½¿ç”¨å®Œæ¯•åå½’è¿˜å¯¹è±¡
result_pool.return_object(result)
```

### å†…å­˜ç›‘æ§

```python
import psutil
import gc

class MemoryMonitor:
    """å†…å­˜ç›‘æ§å™¨"""
    
    def __init__(self, threshold_mb=500):
        self.threshold_mb = threshold_mb
        self.threshold_bytes = threshold_mb * 1024 * 1024
        self.monitoring = False
        self.stats = []
    
    def start_monitoring(self, interval=30):
        """å¼€å§‹å†…å­˜ç›‘æ§"""
        self.monitoring = True
        
        def monitor_loop():
            while self.monitoring:
                self._collect_memory_stats()
                time.sleep(interval)
        
        monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        monitor_thread.start()
        print(f"ğŸ“Š å†…å­˜ç›‘æ§å·²å¯åŠ¨ (é˜ˆå€¼: {self.threshold_mb}MB)")
    
    def stop_monitoring(self):
        """åœæ­¢å†…å­˜ç›‘æ§"""
        self.monitoring = False
        print("ğŸ“Š å†…å­˜ç›‘æ§å·²åœæ­¢")
    
    def _collect_memory_stats(self):
        """æ”¶é›†å†…å­˜ç»Ÿè®¡"""
        process = psutil.Process()
        memory_info = process.memory_info()
        
        stats = {
            "timestamp": time.time(),
            "rss_mb": memory_info.rss / 1024 / 1024,
            "vms_mb": memory_info.vms / 1024 / 1024,
            "percent": process.memory_percent(),
            "gc_objects": len(gc.get_objects())
        }
        
        self.stats.append(stats)
        
        # ä¿ç•™æœ€è¿‘100ä¸ªæ•°æ®ç‚¹
        if len(self.stats) > 100:
            self.stats = self.stats[-100:]
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        if memory_info.rss > self.threshold_bytes:
            self._handle_high_memory(stats)
    
    def _handle_high_memory(self, stats):
        """å¤„ç†é«˜å†…å­˜ä½¿ç”¨"""
        print(f"âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜: {stats['rss_mb']:.1f}MB")
        
        # è§¦å‘åƒåœ¾å›æ”¶
        collected = gc.collect()
        print(f"ğŸ—‘ï¸ åƒåœ¾å›æ”¶: æ¸…ç†äº† {collected} ä¸ªå¯¹è±¡")
        
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–å†…å­˜ä¼˜åŒ–æªæ–½
        self._optimize_memory()
    
    def _optimize_memory(self):
        """å†…å­˜ä¼˜åŒ–æªæ–½"""
        # æ¸…ç†ç¼“å­˜
        if hasattr(self, 'store') and hasattr(self.store, 'clear_cache'):
            self.store.clear_cache()
            print("ğŸ§¹ å·²æ¸…ç†ç¼“å­˜")
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        for generation in range(3):
            gc.collect(generation)
    
    def get_memory_summary(self):
        """è·å–å†…å­˜æ‘˜è¦"""
        if not self.stats:
            return None
        
        recent_stats = self.stats[-10:]  # æœ€è¿‘10ä¸ªæ•°æ®ç‚¹
        
        return {
            "current_rss_mb": recent_stats[-1]["rss_mb"],
            "current_percent": recent_stats[-1]["percent"],
            "avg_rss_mb": sum(s["rss_mb"] for s in recent_stats) / len(recent_stats),
            "max_rss_mb": max(s["rss_mb"] for s in recent_stats),
            "gc_objects": recent_stats[-1]["gc_objects"]
        }

# ä½¿ç”¨å†…å­˜ç›‘æ§
memory_monitor = MemoryMonitor(threshold_mb=200)
memory_monitor.start_monitoring(interval=10)

# è¿è¡Œä¸€æ®µæ—¶é—´åæŸ¥çœ‹æ‘˜è¦
time.sleep(30)
summary = memory_monitor.get_memory_summary()
if summary:
    print(f"ğŸ’¾ å†…å­˜æ‘˜è¦: å½“å‰ {summary['current_rss_mb']:.1f}MB, å¹³å‡ {summary['avg_rss_mb']:.1f}MB")

memory_monitor.stop_monitoring()
```

## ğŸ”§ æ€§èƒ½è°ƒä¼˜é…ç½®

### å…¨å±€æ€§èƒ½é…ç½®

```python
class PerformanceConfig:
    """æ€§èƒ½é…ç½®"""
    
    def __init__(self):
        # è¿æ¥é…ç½®
        self.connection_pool_size = 10
        self.connection_timeout = 30
        self.read_timeout = 60
        
        # è°ƒç”¨é…ç½®
        self.default_batch_size = 10
        self.max_concurrent_calls = 20
        self.call_timeout = 30
        
        # ç¼“å­˜é…ç½®
        self.enable_result_cache = True
        self.cache_size = 1000
        self.cache_ttl = 300
        
        # å†…å­˜é…ç½®
        self.memory_threshold_mb = 500
        self.gc_threshold = 1000
        
        # ç›‘æ§é…ç½®
        self.enable_performance_monitoring = True
        self.monitoring_interval = 30

def apply_performance_config(store, config):
    """åº”ç”¨æ€§èƒ½é…ç½®"""
    
    # é…ç½®è¿æ¥æ± 
    store.configure_connection_pool(
        size=config.connection_pool_size,
        timeout=config.connection_timeout
    )
    
    # é…ç½®ç¼“å­˜
    if config.enable_result_cache:
        store.enable_result_cache(
            size=config.cache_size,
            ttl=config.cache_ttl
        )
    
    # é…ç½®ç›‘æ§
    if config.enable_performance_monitoring:
        store.enable_performance_monitoring(
            interval=config.monitoring_interval
        )
    
    print("âš¡ æ€§èƒ½é…ç½®å·²åº”ç”¨")

# ä½¿ç”¨æ€§èƒ½é…ç½®
perf_config = PerformanceConfig()
apply_performance_config(store, perf_config)
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```python
class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    def __init__(self, store):
        self.store = store
        self.results = {}
    
    def run_benchmark(self, test_name, test_func, iterations=100):
        """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
        print(f"ğŸƒ è¿è¡ŒåŸºå‡†æµ‹è¯•: {test_name}")
        
        times = []
        errors = 0
        
        for i in range(iterations):
            try:
                start_time = time.time()
                test_func()
                end_time = time.time()
                times.append(end_time - start_time)
            except Exception as e:
                errors += 1
                print(f"âŒ æµ‹è¯•è¿­ä»£ {i+1} å¤±è´¥: {e}")
        
        if times:
            self.results[test_name] = {
                "iterations": len(times),
                "errors": errors,
                "avg_time": sum(times) / len(times),
                "min_time": min(times),
                "max_time": max(times),
                "total_time": sum(times),
                "success_rate": len(times) / iterations * 100
            }
        
        return self.results[test_name]
    
    def print_results(self):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print("\nğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:")
        print("=" * 60)
        
        for test_name, result in self.results.items():
            print(f"\nğŸ” {test_name}:")
            print(f"   è¿­ä»£æ¬¡æ•°: {result['iterations']}")
            print(f"   æˆåŠŸç‡: {result['success_rate']:.1f}%")
            print(f"   å¹³å‡æ—¶é—´: {result['avg_time']*1000:.2f}ms")
            print(f"   æœ€å°æ—¶é—´: {result['min_time']*1000:.2f}ms")
            print(f"   æœ€å¤§æ—¶é—´: {result['max_time']*1000:.2f}ms")
            print(f"   æ€»æ—¶é—´: {result['total_time']:.2f}s")

# å®šä¹‰æµ‹è¯•å‡½æ•°
def test_simple_call():
    """ç®€å•è°ƒç”¨æµ‹è¯•"""
    store.call_tool("list_directory", {"path": "/tmp"})

def test_batch_call():
    """æ‰¹é‡è°ƒç”¨æµ‹è¯•"""
    calls = [
        {"tool_name": "list_directory", "arguments": {"path": "/tmp"}}
        for _ in range(5)
    ]
    store.batch_call(calls)

# è¿è¡ŒåŸºå‡†æµ‹è¯•
benchmark = PerformanceBenchmark(store)

benchmark.run_benchmark("ç®€å•è°ƒç”¨", test_simple_call, iterations=50)
benchmark.run_benchmark("æ‰¹é‡è°ƒç”¨", test_batch_call, iterations=20)

benchmark.print_results()
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [ç›‘æ§ç³»ç»Ÿ](monitoring.md)
- [é”™è¯¯å¤„ç†](error-handling.md)
- [æ‰¹é‡è°ƒç”¨](../tools/usage/batch-call.md)
- [é“¾å¼è°ƒç”¨](chaining.md)

## ğŸ“š æœ€ä½³å®è·µ

1. **è¿æ¥ç®¡ç†**ï¼šä½¿ç”¨è¿æ¥æ± ï¼Œé¿å…é¢‘ç¹åˆ›å»ºè¿æ¥
2. **æ‰¹é‡æ“ä½œ**ï¼šåˆå¹¶å¤šä¸ªè°ƒç”¨ï¼Œå‡å°‘ç½‘ç»œå¼€é”€
3. **å¼‚æ­¥å¤„ç†**ï¼šä½¿ç”¨å¼‚æ­¥è°ƒç”¨æé«˜å¹¶å‘æ€§èƒ½
4. **ç¼“å­˜ç­–ç•¥**ï¼šç¼“å­˜é¢‘ç¹è®¿é—®çš„ç»“æœ
5. **å†…å­˜ç®¡ç†**ï¼šç›‘æ§å†…å­˜ä½¿ç”¨ï¼ŒåŠæ—¶æ¸…ç†èµ„æº
6. **æ€§èƒ½ç›‘æ§**ï¼šå»ºç«‹æ€§èƒ½åŸºå‡†ï¼ŒæŒç»­ä¼˜åŒ–

---

**æ›´æ–°æ—¶é—´**: 2025-01-09  
**ç‰ˆæœ¬**: 1.0.0
